# -*- coding: utf-8 -*-
"""Untitled10.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JczJ4ujQ4NYOqdbnjfIOp_J4UZA8NkO7

# ðŸ“° Fake News Generator and Detector using NLP and GPT-2

This project combines Natural Language Processing (NLP) and Machine Learning to generate and detect fake news.

- The **generator** uses GPT-2 to create fake news headlines from a user-provided prompt.
- The **detector** uses TF-IDF and Logistic Regression to classify news as either **FAKE** or **REAL**.
- A Gradio interface allows interactive use of both components.

Built entirely in Python using libraries like `transformers`, `scikit-learn`, and `gradio`.
"""

import pandas as pd
df=pd.read_csv("/content/fake_and_real_news_dataset.csv")

df.head()

df.info()

df.isnull().sum()

df=df.fillna('')

df.isnull().sum()

df.columns

df=df.drop(['idd', 'title'], axis=1)
df.head()

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
import re
port_stem=PorterStemmer()

stop_words = set(stopwords.words('english'))
def stemming(content):
  con=re.sub('[^a-zA-Z]', ' ', content)
  con=con.lower()
  con=con.split()
  con=[port_stem.stem(word) for word in con if word not in stop_words]
  con=' '.join(con)
  return con

df['text'] = df['text'].apply(stemming)

x=df['text']
y=df['label']
y.shape

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)

from sklearn.feature_extraction.text import TfidfVectorizer
vect=TfidfVectorizer()

x_train_vect = vect.fit_transform(x_train)
x_test_vect = vect.transform(x_test)

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(x_train_vect, y_train)

y_pred = model.predict(x_test_vect)

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
print("Acccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))

def predict_news(news_text):
  stemmed = stemming(news_text)
  vect_text=vect.transform([stemmed])
  prediction = model.predict(vect_text)
  return prediction[0]

print(predict_news("Breaking: The government has confirmed new Covid-19 restrictions."))

predict_news("In india in 2014 , bjp won the elections")

#STARTING THE GENERATOR PART OF THE PROJECT FROM HERE
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import torch
model_name = "gpt2"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
generator_model = GPT2LMHeadModel.from_pretrained(model_name)
generator_model.eval()

def generate_fake_news(prompt, max_length=50, num_return_sequences=1):
  input_ids = tokenizer.encode(prompt, return_tensors="pt")
  outputs = generator_model.generate(
      input_ids,
      max_length=max_length,
      num_return_sequences=num_return_sequences,
      no_repeat_ngram_size=2,
      do_sample=True,
      top_k=50,
      top_p=0.9,
      temperature=0.7,
      pad_token_id=tokenizer.eos_token_id
  )
  return tokenizer.decode(outputs[0], skip_special_tokens=True)

prompt = "Breaking News:"
print(generate_fake_news(prompt))

#INTERGRATING BOTH DETECTOR AND GENERATOR CODE TOGETHER
import gradio as gr
def gradio_pipeline(prompt):
  generated_text = generate_fake_news(prompt)
  prediction = predict_news(generated_text)
  return generated_text, prediction
interface = gr.Interface(
    fn = gradio_pipeline,
    inputs = gr.Textbox(lines=2, placeholder="Enter a prompt..."),
    outputs = [
        gr.Textbox(label="Generated Fake News"),
        gr.Textbox(label="Prediction(Fake or Real)")
    ],
    title = "Fake News Generator and Detector",
    description = "Enter a prompt to generate fake news and classify it as FAKE or REAL."
)
interface.launch(debug=True)